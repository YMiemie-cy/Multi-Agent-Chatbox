"""
APIå®¢æˆ·ç«¯å·¥å…·æ¨¡å—
"""
import asyncio
import logging
from typing import Dict, List, Optional, Tuple
import openai
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from config import config

logger = logging.getLogger(__name__)

class APIError(Exception):
    """APIé”™è¯¯åŸºç±»"""
    pass

class APIRateLimitError(APIError):
    """APIé™æµé”™è¯¯"""
    pass

class APIAuthError(APIError):
    """APIè®¤è¯é”™è¯¯"""
    pass

class EnhancedPoeClient:
    """å¢å¼ºçš„Poe APIå®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.client = openai.OpenAI(
            api_key=config.POE_API_KEY,
            base_url=config.POE_BASE_URL,
        )
        self._request_count = 0
        self._last_reset = asyncio.get_event_loop().time()
    
    def _check_rate_limit(self):
        """æ£€æŸ¥è¯·æ±‚é™æµ"""
        current_time = asyncio.get_event_loop().time()
        
        # é‡ç½®è®¡æ•°å™¨
        if current_time - self._last_reset > config.RATE_LIMIT_WINDOW:
            self._request_count = 0
            self._last_reset = current_time
        
        if self._request_count >= config.RATE_LIMIT_REQUESTS:
            raise APIRateLimitError("è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åå†è¯•")
        
        self._request_count += 1
    
    async def stream_chat_completion(
        self,
        model: str,
        messages: List[Dict],
        max_tokens: int = None,
        temperature: float = None,
        **kwargs
    ):
        """æµå¼èŠå¤©å®ŒæˆAPIè°ƒç”¨"""
        try:
            self._check_rate_limit()
            
            logger.info(f"ğŸ” å‡†å¤‡æµå¼è°ƒç”¨API: {model}")
            
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=max_tokens or config.DEFAULT_MAX_TOKENS,
                temperature=temperature or config.DEFAULT_TEMPERATURE,
                stream=True,
                **kwargs
            )
            
            for chunk in response:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
            
            logger.info(f"âœ… æµå¼APIè°ƒç”¨å®Œæˆ: {model}")
            
        except Exception as e:
            logger.error(f"æµå¼è°ƒç”¨å¤±è´¥: {e}")
            raise APIError(f"æµå¼è¯·æ±‚å¤±è´¥: {e}")

    @retry(
        stop=stop_after_attempt(config.MAX_RETRIES),
        wait=wait_exponential(multiplier=1, min=1, max=10),
        retry=retry_if_exception_type((APIRateLimitError, ConnectionError))
    )
    async def chat_completion(
        self,
        model: str,
        messages: List[Dict],
        max_tokens: int = None,
        temperature: float = None,
        **kwargs
    ) -> str:
        """èŠå¤©å®ŒæˆAPIè°ƒç”¨"""
        try:
            self._check_rate_limit()
            
            # è°ƒè¯•ï¼šè®°å½•æ¶ˆæ¯ç»“æ„
            logger.info(f"ğŸ” å‡†å¤‡è°ƒç”¨API: {model}")
            logger.info(f"ğŸ” æ¶ˆæ¯æ•°é‡: {len(messages)}")
            for i, msg in enumerate(messages):
                logger.info(f"ğŸ” æ¶ˆæ¯ {i}: role={msg.get('role')}, contentç±»å‹={type(msg.get('content'))}")
                if isinstance(msg.get('content'), list):
                    logger.info(f"ğŸ”   å¤šæ¨¡æ€æ¶ˆæ¯ï¼ŒåŒ…å« {len(msg['content'])} ä¸ªéƒ¨åˆ†")
                    for j, part in enumerate(msg['content']):
                        part_type = part.get('type')
                        logger.info(f"ğŸ”     éƒ¨åˆ† {j}: type={part_type}")
                        if part_type == 'image_url':
                            url = part.get('image_url', {}).get('url', '')
                            logger.info(f"ğŸ”       å›¾ç‰‡URLå‰50å­—ç¬¦: {url[:50]}")
                        elif part_type == 'text':
                            text = part.get('text', '')
                            logger.info(f"ğŸ”       æ–‡æœ¬é•¿åº¦: {len(text)}, å‰100å­—ç¬¦: {text[:100]}")
            
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=max_tokens or config.DEFAULT_MAX_TOKENS,
                temperature=temperature or config.DEFAULT_TEMPERATURE,
                stream=False,
                **kwargs
            )
            
            content = response.choices[0].message.content or ""
            logger.info(f"âœ… APIè°ƒç”¨æˆåŠŸ: {model}, è¿”å›å†…å®¹é•¿åº¦: {len(content)}")
            logger.info(f"âœ… è¿”å›å†…å®¹å‰200å­—ç¬¦: {content[:200]}")
            return content
            
        except openai.AuthenticationError as e:
            logger.error(f"APIè®¤è¯å¤±è´¥: {e}")
            raise APIAuthError("APIå¯†é’¥æ— æ•ˆæˆ–è¿‡æœŸ")
            
        except openai.RateLimitError as e:
            logger.warning(f"APIé™æµ: {e}")
            raise APIRateLimitError("APIè¯·æ±‚é¢‘ç‡è¶…é™")
            
        except openai.APIError as e:
            logger.error(f"APIé”™è¯¯: {e}")
            if "403" in str(e):
                raise APIAuthError("APIè®¿é—®è¢«æ‹’ç»ï¼Œè¯·æ£€æŸ¥å¯†é’¥æƒé™")
            raise APIError(f"APIè°ƒç”¨å¤±è´¥: {e}")
            
        except Exception as e:
            logger.error(f"æœªçŸ¥é”™è¯¯: {e}")
            raise APIError(f"è¯·æ±‚å¤±è´¥: {e}")
    
    async def health_check(self) -> bool:
        """APIå¥åº·æ£€æŸ¥"""
        try:
            await self.chat_completion(
                model="GPT-4o",
                messages=[{"role": "user", "content": "test"}],
                max_tokens=10
            )
            return True
        except Exception as e:
            logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False

# å…¨å±€å®¢æˆ·ç«¯å®ä¾‹
poe_client = EnhancedPoeClient()

